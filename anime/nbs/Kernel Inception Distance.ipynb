{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp anime.kid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fast.torch_basics import *\n",
    "from fast.metrics import *\n",
    "from fast.learner import *\n",
    "from torchvision.models.inception import Inception3\n",
    "from sklearn.metrics.pairwise import polynomial_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#Reimplimentation to allow more hooks, only works for eval, not accurate for training\n",
    "class Inception_v3(Inception3):\n",
    "    def __init__(self):\n",
    "        super(Inception_v3, self).__init__()\n",
    "        self.pool3=nn.AdaptiveAvgPool2d((1, 1))\n",
    "        #not using nn.Sequential as would double register parameters\n",
    "        self.seq_modules=[self.Conv2d_1a_3x3,\n",
    "            self.Conv2d_2a_3x3,\n",
    "            self.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(3,2),\n",
    "            self.Conv2d_3b_1x1,\n",
    "            self.Conv2d_4a_3x3,\n",
    "            nn.MaxPool2d(3,2),\n",
    "            self.Mixed_5b,\n",
    "            self.Mixed_5c,\n",
    "            self.Mixed_5d,\n",
    "            self.Mixed_6a,\n",
    "            self.Mixed_6b,\n",
    "            self.Mixed_6c,\n",
    "            self.Mixed_6d,\n",
    "            self.Mixed_6e,\n",
    "            self.Mixed_7a,\n",
    "            self.Mixed_7b,\n",
    "            self.Mixed_7c,\n",
    "            self.pool3,\n",
    "            partial(F.dropout,training=False),\n",
    "            nn.Flatten(1),\n",
    "            self.fc]\n",
    "    def forward(self, x):\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        for mod in self.seq_modules:\n",
    "            x = mod(x)\n",
    "        return x\n",
    "\n",
    "class KernelInceptionDistanceMetric(Metric):\n",
    "    def __init__(self,targs):\n",
    "        state = torch.hub.load('pytorch/vision:v0.4.2', 'inception_v3', pretrained=True).state_dict()\n",
    "        inception=Inception_v3()\n",
    "        inception.load_state_dict(state)\n",
    "        inception.seq_modules=inception.seq_modules[0:-3] #removing layers up to pool3\n",
    "        self.kid=KernelInceptionDistance(inception,targs)\n",
    "        self.preds=[]\n",
    "    def accumulate(self, learn):\n",
    "        self.preds+=learn.pred.detach().cpu()\n",
    "    def reset(self): \n",
    "        self.preds=[]\n",
    "    @property\n",
    "    def value(self):\n",
    "        samples = self.kid(self.preds)\n",
    "        means,stds = samples[:,0],samples[:,1]\n",
    "        return means.mean(),means.std(),stds.mean(),stds.std()\n",
    "\n",
    "class KIDCallback(Callback):\n",
    "    def __init__(self,targs):\n",
    "        self.kid=KernelInceptionDistanceMetric(targs)\n",
    "    def batch_end(self):\n",
    "        self.kid.accumulate(self.learn)\n",
    "    def valid_end(self):\n",
    "        self.kid.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class KernelInceptionDistance():\n",
    "    # Images expected as [ b, channels, width, height \n",
    "    def __init__(self, model, images):\n",
    "        self.model=model\n",
    "        self.targs=array([self._inception_activations(imgs).numpy() for imgs in self._reshape_imgs(images)]).reshape(len(images),2048)\n",
    "    \n",
    "    def __call__(self,preds,subsets=100,subset_size=1000):\n",
    "        preds=array([self._inception_activations(imgs).numpy() for imgs in self._reshape_imgs(preds)]).reshape(len(preds),2048) #[bs,2048] output expected from inception\n",
    "        results=[]\n",
    "        for i in range(subsets):\n",
    "            t=np.random.choice(len(self.targs), subset_size, replace=False)\n",
    "            p=np.random.choice(len(preds), subset_size, replace=False)\n",
    "            results+=[self._polynomial_mmd(self.targs[t],preds[p])]\n",
    "        return array(results)\n",
    "    \n",
    "    def _inception_activations(self,imgs):\n",
    "        with torch.no_grad(): \n",
    "            return self.model(imgs).detach()[...,0,0]\n",
    "    def _reshape_imgs(self,images,num=100):\n",
    "        return images.reshape(len(images)//num,num,3,299,299)\n",
    "    def _polynomial_mmd(self,codes_g, codes_r, degree=3, gamma=None, coef0=1,\n",
    "                       var_at_m=None, ret_var=True):\n",
    "        # use  k(x, y) = (gamma <x, y> + coef0)^degree\n",
    "        # default gamma is 1 / dim\n",
    "        X = codes_g\n",
    "        Y = codes_r\n",
    "\n",
    "        K_XX = polynomial_kernel(X, degree=degree, gamma=gamma, coef0=coef0)\n",
    "        K_YY = polynomial_kernel(Y, degree=degree, gamma=gamma, coef0=coef0)\n",
    "        K_XY = polynomial_kernel(X, Y, degree=degree, gamma=gamma, coef0=coef0)\n",
    "\n",
    "        return self._mmd2_and_variance(K_XX, K_XY, K_YY,\n",
    "            var_at_m=var_at_m, ret_var=ret_var)\n",
    "    def _sqn(self,arr):\n",
    "        flat = np.ravel(arr)\n",
    "        return flat.dot(flat)\n",
    "    def _mmd2_and_variance(self,K_XX, K_XY, K_YY, unit_diagonal=False,\n",
    "                           mmd_est='unbiased', block_size=1024,\n",
    "                           var_at_m=None, ret_var=True):\n",
    "        # based on\n",
    "        # https://github.com/dougalsutherland/opt-mmd/blob/master/two_sample/mmd.py\n",
    "        # but changed to not compute the full kernel matrix at once\n",
    "        m = K_XX.shape[0]\n",
    "        assert K_XX.shape == (m, m)\n",
    "        assert K_XY.shape == (m, m)\n",
    "        assert K_YY.shape == (m, m)\n",
    "        if var_at_m is None:\n",
    "            var_at_m = m\n",
    "\n",
    "        # Get the various sums of kernels that we'll use\n",
    "        # Kts drop the diagonal, but we don't need to compute them explicitly\n",
    "        if unit_diagonal:\n",
    "            diag_X = diag_Y = 1\n",
    "            sum_diag_X = sum_diag_Y = m\n",
    "            sum_diag2_X = sum_diag2_Y = m\n",
    "        else:\n",
    "            diag_X = np.diagonal(K_XX)\n",
    "            diag_Y = np.diagonal(K_YY)\n",
    "\n",
    "            sum_diag_X = diag_X.sum()\n",
    "            sum_diag_Y = diag_Y.sum()\n",
    "\n",
    "            sum_diag2_X = self._sqn(diag_X)\n",
    "            sum_diag2_Y = self._sqn(diag_Y)\n",
    "\n",
    "        Kt_XX_sums = K_XX.sum(axis=1) - diag_X\n",
    "        Kt_YY_sums = K_YY.sum(axis=1) - diag_Y\n",
    "        K_XY_sums_0 = K_XY.sum(axis=0)\n",
    "        K_XY_sums_1 = K_XY.sum(axis=1)\n",
    "\n",
    "        Kt_XX_sum = Kt_XX_sums.sum()\n",
    "        Kt_YY_sum = Kt_YY_sums.sum()\n",
    "        K_XY_sum = K_XY_sums_0.sum()\n",
    "\n",
    "        if mmd_est == 'biased':\n",
    "            mmd2 = ((Kt_XX_sum + sum_diag_X) / (m * m)\n",
    "                    + (Kt_YY_sum + sum_diag_Y) / (m * m)\n",
    "                    - 2 * K_XY_sum / (m * m))\n",
    "        else:\n",
    "            assert mmd_est in {'unbiased', 'u-statistic'}\n",
    "            mmd2 = (Kt_XX_sum + Kt_YY_sum) / (m * (m-1))\n",
    "            if mmd_est == 'unbiased':\n",
    "                mmd2 -= 2 * K_XY_sum / (m * m)\n",
    "            else:\n",
    "                mmd2 -= 2 * (K_XY_sum - np.trace(K_XY)) / (m * (m-1))\n",
    "\n",
    "        if not ret_var:\n",
    "            return mmd2\n",
    "\n",
    "        Kt_XX_2_sum = self._sqn(K_XX) - sum_diag2_X\n",
    "        Kt_YY_2_sum = self._sqn(K_YY) - sum_diag2_Y\n",
    "        K_XY_2_sum = self._sqn(K_XY)\n",
    "\n",
    "        dot_XX_XY = Kt_XX_sums.dot(K_XY_sums_1)\n",
    "        dot_YY_YX = Kt_YY_sums.dot(K_XY_sums_0)\n",
    "\n",
    "        m1 = m - 1\n",
    "        m2 = m - 2\n",
    "        zeta1_est = (\n",
    "            1 / (m * m1 * m2) * (\n",
    "                self._sqn(Kt_XX_sums) - Kt_XX_2_sum + self._sqn(Kt_YY_sums) - Kt_YY_2_sum)\n",
    "            - 1 / (m * m1)**2 * (Kt_XX_sum**2 + Kt_YY_sum**2)\n",
    "            + 1 / (m * m * m1) * (\n",
    "                self._sqn(K_XY_sums_1) + self._sqn(K_XY_sums_0) - 2 * K_XY_2_sum)\n",
    "            - 2 / m**4 * K_XY_sum**2\n",
    "            - 2 / (m * m * m1) * (dot_XX_XY + dot_YY_YX)\n",
    "            + 2 / (m**3 * m1) * (Kt_XX_sum + Kt_YY_sum) * K_XY_sum\n",
    "        )\n",
    "        zeta2_est = (\n",
    "            1 / (m * m1) * (Kt_XX_2_sum + Kt_YY_2_sum)\n",
    "            - 1 / (m * m1)**2 * (Kt_XX_sum**2 + Kt_YY_sum**2)\n",
    "            + 2 / (m * m) * K_XY_2_sum\n",
    "            - 2 / m**4 * K_XY_sum**2\n",
    "            - 4 / (m * m * m1) * (dot_XX_XY + dot_YY_YX)\n",
    "            + 4 / (m**3 * m1) * (Kt_XX_sum + Kt_YY_sum) * K_XY_sum\n",
    "        )\n",
    "        var_est = (4 * (var_at_m - 2) / (var_at_m * (var_at_m - 1)) * zeta1_est\n",
    "                   + 2 / (var_at_m * (var_at_m - 1)) * zeta2_est)\n",
    "\n",
    "        return mmd2, var_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fast/.cache/torch/hub/pytorch_vision_v0.4.2\n"
     ]
    }
   ],
   "source": [
    "state = torch.hub.load('pytorch/vision:v0.4.2', 'inception_v3', pretrained=True).state_dict()\n",
    "inception=Inception_v3()\n",
    "inception.load_state_dict(state)\n",
    "inception.seq_modules=inception.seq_modules[0:-3] #removing layers up to pool3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path(\"/home/fast/.fastai/data/danbooru2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfie_imgs=[]\n",
    "with open(path/'selfie_mmd_test_full.npy', 'rb') as f:\n",
    "   selfie_imgs=np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_imgs=[]\n",
    "with open(path/'anime_mmd_test_full.npy', 'rb') as f:\n",
    "   anime_imgs=np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kid = KernelInceptionDistance(inception,Tensor(anime_imgs.reshape(3400,3,299,299)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.09724725e-05, -2.10227725e-08],\n",
       "       [-2.33440941e-05, -2.10831747e-08],\n",
       "       [-6.21251251e-05, -1.81319467e-08],\n",
       "       [-8.30162663e-05, -2.24762155e-08],\n",
       "       [-7.35260260e-05, -2.14923515e-08],\n",
       "       [-9.67124625e-05, -1.99856415e-08],\n",
       "       [-9.88083083e-05, -1.96475778e-08],\n",
       "       [-1.08430180e-04, -2.26157290e-08],\n",
       "       [-1.45734234e-04, -2.01962180e-08],\n",
       "       [-1.13360110e-04, -2.09984027e-08],\n",
       "       [-1.20378879e-04, -2.38314152e-08],\n",
       "       [-1.29276777e-04, -2.26356037e-08],\n",
       "       [-1.17204705e-04, -1.65683061e-08],\n",
       "       [-1.10112112e-04, -2.04787056e-08],\n",
       "       [-1.09458709e-04, -1.99636885e-08],\n",
       "       [-1.26397898e-04, -2.40292361e-08],\n",
       "       [-1.08704454e-04, -2.07743792e-08],\n",
       "       [-9.35190190e-05, -2.19159081e-08],\n",
       "       [-7.12567568e-05, -2.00620177e-08],\n",
       "       [-9.05027528e-05, -2.05180839e-08],\n",
       "       [-1.17563564e-04, -2.03607915e-08],\n",
       "       [-8.44169169e-05, -1.65280018e-08],\n",
       "       [-1.02600601e-04, -2.39787728e-08],\n",
       "       [-7.35705706e-05, -2.20982880e-08],\n",
       "       [-1.05708208e-04, -2.08516418e-08],\n",
       "       [-7.72727728e-05, -2.00088914e-08],\n",
       "       [-5.34149149e-05, -2.38390730e-08],\n",
       "       [-4.86811812e-05, -1.85883186e-08],\n",
       "       [-1.32876877e-04, -1.91664566e-08],\n",
       "       [-1.11934434e-04, -2.45486348e-08],\n",
       "       [-1.41140390e-04, -2.27263949e-08],\n",
       "       [-1.49283534e-04, -2.17584317e-08],\n",
       "       [-7.09081582e-05, -2.06071503e-08],\n",
       "       [-7.55115115e-05, -2.07108818e-08],\n",
       "       [-7.25025025e-06, -1.83436925e-08],\n",
       "       [-9.90495495e-05, -2.16830873e-08],\n",
       "       [-1.24197948e-04, -2.21875289e-08],\n",
       "       [-4.44419419e-05, -2.08944074e-08],\n",
       "       [-1.56426677e-04, -2.35789023e-08],\n",
       "       [-8.92890390e-05, -2.10549371e-08],\n",
       "       [-7.16328829e-05, -2.09952566e-08],\n",
       "       [-1.16722723e-04, -1.99068810e-08],\n",
       "       [-9.76183684e-05, -2.19106623e-08],\n",
       "       [-1.06080581e-04, -2.23992095e-08],\n",
       "       [-9.05395395e-05, -2.16768872e-08],\n",
       "       [-1.10309309e-04, -2.09270959e-08],\n",
       "       [-6.77302302e-05, -1.82895046e-08],\n",
       "       [-1.22155656e-04, -2.38644976e-08],\n",
       "       [-3.11268769e-05, -1.76532439e-08],\n",
       "       [-1.18640891e-04, -2.43225736e-08],\n",
       "       [-1.16417417e-04, -2.17710686e-08],\n",
       "       [-1.05428178e-04, -2.25323069e-08],\n",
       "       [-6.29349349e-05, -1.94729238e-08],\n",
       "       [-9.74181682e-05, -1.91781148e-08],\n",
       "       [-1.01896396e-04, -2.31875579e-08],\n",
       "       [-9.75905906e-05, -2.00513784e-08],\n",
       "       [-1.33588088e-04, -2.51390306e-08],\n",
       "       [-1.13685185e-04, -2.10346596e-08],\n",
       "       [-5.90375375e-05, -1.90098928e-08],\n",
       "       [-1.24906406e-04, -2.12666309e-08],\n",
       "       [-5.72439940e-05, -1.83630921e-08],\n",
       "       [-4.79489489e-05, -1.86345012e-08],\n",
       "       [-1.53868619e-04, -2.33442991e-08],\n",
       "       [-6.54111612e-05, -2.04823680e-08],\n",
       "       [-1.18418919e-04, -2.41379845e-08],\n",
       "       [-1.01797798e-04, -2.32481331e-08],\n",
       "       [-9.97762763e-05, -2.38345802e-08],\n",
       "       [-1.05396146e-04, -1.91687606e-08],\n",
       "       [-9.50553053e-05, -2.05465465e-08],\n",
       "       [-8.29479479e-05, -1.98169955e-08],\n",
       "       [-7.14254254e-05, -2.09953680e-08],\n",
       "       [-8.55452953e-05, -2.20163539e-08],\n",
       "       [-1.76508008e-04, -2.38248599e-08],\n",
       "       [-5.72457457e-05, -2.02097061e-08],\n",
       "       [-2.11076076e-05, -2.06201467e-08],\n",
       "       [-1.11286286e-04, -2.01840004e-08],\n",
       "       [-5.95425425e-05, -1.79867131e-08],\n",
       "       [-7.19819820e-05, -2.52254039e-08],\n",
       "       [-6.06403904e-05, -2.07198742e-08],\n",
       "       [-6.85350350e-05, -2.16161175e-08],\n",
       "       [-8.02407407e-05, -1.91628122e-08],\n",
       "       [-7.73598599e-05, -1.91736827e-08],\n",
       "       [-1.27880130e-04, -2.15566365e-08],\n",
       "       [-9.58891391e-05, -2.35496582e-08],\n",
       "       [-9.44136637e-05, -2.15727288e-08],\n",
       "       [-1.03945946e-04, -2.16933629e-08],\n",
       "       [-8.13140641e-05, -2.19812202e-08],\n",
       "       [-1.06134134e-04, -2.09649693e-08],\n",
       "       [-1.17680430e-04, -2.29009458e-08],\n",
       "       [-5.69559560e-05, -2.09072973e-08],\n",
       "       [-1.07156907e-04, -1.82403453e-08],\n",
       "       [-9.34697197e-05, -2.24918210e-08],\n",
       "       [-5.04822322e-05, -1.99079732e-08],\n",
       "       [-1.44897648e-04, -2.19555380e-08],\n",
       "       [-1.11188188e-04, -2.20588156e-08],\n",
       "       [-1.09491992e-04, -1.93205426e-08],\n",
       "       [-9.72122122e-05, -2.17674848e-08],\n",
       "       [-7.91961962e-05, -1.93133949e-08],\n",
       "       [-9.07152152e-05, -2.22492493e-08],\n",
       "       [-1.37853854e-04, -2.16713480e-08]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kid(Tensor(selfie_imgs.reshape(3400,3,299,299)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#from fast.notebook.export import notebook2script\n",
    "#notebook2script(all_fs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
