---
keywords: fastai
description: "Hello, this is one of my full-time self learning projects. This was done in fastai2⁹, my GPU setups for this will be two 2070 Supers. The goal of this was to use fp16 training on U-GAT-IT. I did not do any of this in a controlled and meticulous experiment fashion. While I do agree that this is very important, I found that I had to forgo this in order to get something working. For the first two months of this I did not even have a working model for example. The target audience for this post is someone with either a single MOOC or introductory deep learning class, if you are in this category and do not understand something, feel free to leave a comment and I will try to answer your question, and update the article to be clearer. If you do not have any knowledge on deep learning this article might be a bit difficult, feel free to ask questions and I will do the best to answer them, and I really recommend learning fastai at https://course.fast.ai/"
title: "Training UGATIT in FP16"
toc: true
branch: master
badges: true
comments: true
author: Molly Beavers
categories: [fastpages, jupyter]
nb_path: nbs/Blog_Post.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/Blog_Post.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev</span> <span class="kn">import</span> <span class="n">export2html</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-U-GAT-IT-with-fp16">Training U-GAT-IT with fp16<a class="anchor-link" href="#Training-U-GAT-IT-with-fp16"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Hello, this is one of my full-time self learning projects. This was done in fastai2⁹, my GPU setups for this will be two 2070 Supers. The goal of this was to use fp16 training on U-GAT-IT. I did not do any of this in a controlled and meticulous experiment fashion. While I do agree that this is very important, I found that I had to forgo this in order to get something working. For the first two months of this I did not even have a working model for example. The target audience for this post is someone with either a single MOOC or introductory deep learning class, if you are in this category and do not understand something, feel free to leave a comment and I will try to answer your question, and update the article to be clearer. If you do not have any knowledge on deep learning this article might be a bit difficult, feel free to ask questions and I will do the best to answer them, and I really recommend learning fastai at <a href="https://course.fast.ai/">https://course.fast.ai/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Prior-Work">Prior Work<a class="anchor-link" href="#Prior-Work"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>GANs³ are generational adversarial networks, or in this case, a network than generates images, and another network that tells if it is real or fake. The two networks then compete to be better than the other, and that is how we get a network that can generate images. CycleGan² in based off of this idea, but the generators take an image as input, the output of a generator is sent through the second generator, and and the output of the second generator must match the input of the first generator. This way a generator can't learn to simply generate an image regardless of its input, and must encode information from the original image all throughout the whole "Cycle".
Network architecture for The Generator of U-GAT-IT¹Network architecture for The Discriminator of U-GAT-IT¹This post is based on the U-GAT-IT¹ architecture above, and is a project I worked on in order to get U-GAT-IT training on my GPUs in fp16. U-GAT-IT showed good results on anime based images. It introduces a few things, such as the selfie2anime dataset, adaptive layer-instance norm, Class-Activation Map Loss, and more. Those who have seen the 2019 fastai course should know that Class Activation Mapping is how you get a heatmap of your network activating on a particular image. The architecture of the network is based on Cycle GAN, and has a total of two generators and four discriminators. 
U-GAT-IT Results¹</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="FP16">FP16<a class="anchor-link" href="#FP16"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Getting fp16 training working for U-GAT-IT was definitely what I spent the majority of the past few months doing. To get this to work I needed to use Mixed Precision Training⁴. I tried many things, but eventually found that the "most" code, with the "most" complicated looking training loop was the way to go, definitely something I am not used to saying. This meant that many of my earlier simpler but unsuccessful experiments meant that I was very disheartened by the time I actually got anything working. This "complicated" way was implementing loss scaling separately for both the generators and discriminator of U-GAT-IT. This came with challenges about how to handle overflow and tracking all the variables associated with loss scaling separately.
Reduced range in fp16⁴Now I will start with a few definitions, fp16 overflow is when your gradients are too big too fit within fp16. Underflow is when fp16 gradients are so close to 0 that they are simply rounded to 0. Overflow and underflow can happen in fp32 as well, but isn't nearly as big of a problem because fp32 is simply "bigger." Loss scaling is multiplying our loss by as large a value as possible,which effectively is multiplied by our gradients. This avoids underflow by increasing the gradients, but we need to make sure it is not big enough that it causes an overflow. One technicality to loss scaling is calculating the loss itself in fp32, because calculating a loss includes division and low precision division is very in-precise leading to unstable gradients/training. Another technicality is that the gradients have to be divided by the loss scale, to keep the magnitudes consistent with a fp32-bit model, otherwise this would be very similar to simply increasing the learning rate by the loss scale! But, wait a minute… if we divide by the loss scale won't we just run into the underflow issue from before? Your right, we have to have a fp32 copy of the weights as well, so that we can avoid this problem. We copy the scaled gradients over to an fp32 model and then divide by the loss scale there. We then continue the optimization step in fp32.
So, I haven't talked about how I handled overflow yet, because that actually gets into the GAN specifics of the training loop. I found that the discriminator was unable to converge without a fairly high loss scale, and the generator overflowed at a comparatively low loss scale. This was because the generator has a much higher loss, but I will get into that latter, or you can skip to "Tanh Loss". This differing requirement of loss scale means that we need to track the loss scale separately for the generator and discriminator. We also have two states for overflow failure, overflow in the generator, and overflow in the discriminator. In the case of the discriminator I simply grab another set of samples from the training set, and generate a new fake and compare to real as usual. For a generator overflow, I simply skip to the next batch. Skipping to the next batch is a problem because the total number of successfully run batches is not accounted for currently in my training loop, so there is some variations in the amount of training done, I would like to fix this in the future.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Batch-Size-of-3">Batch Size of 3<a class="anchor-link" href="#Batch-Size-of-3"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch size of three was the maximum I could reasonably get out of my model, given memory limitations. In a GAN architecture there are trade offs of increasing the batch size, as it might allow a network to learn too much before the other gets a chance to train. I found that in my case, the very first convolution layer had a tendency to overflow, at fairly irregular intervals. Increasing the batch size to three mostly smoothed this out so that I could have orders of magnitude higher loss scale.</p>
<p>&lt;insert graph of loss scale batch size 2&gt;&lt;insert graph of loss scale batch size 3&gt;</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2-category-Categorical-Cross-Entropy-VS-Binary-Cross-Entropy-with-Logits">2-category Categorical Cross Entropy VS Binary Cross Entropy with Logits<a class="anchor-link" href="#2-category-Categorical-Cross-Entropy-VS-Binary-Cross-Entropy-with-Logits"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For people not overly familiar with loss functions, Categorical Cross Entropy is the loss function generally used for selecting a single category, out of many. Examples of tasks that use Categorical Cross Entropy are Imagenet Classification or Dog vs Cat. Dog vs Cat is a special case, because there are only two choices, Dog or Cat, this is what I am referring to when I say 2-category Categorical Cross Entropy. Binary Cross Entropy with Logits is very similar, but uses a Sigmoid into a Binary Cross Entropy Loss, which is calculating loss based on distance from either 0 or 1. This means that Categorical Cross Entropy requires 2 values one for each category, and Binary cross entropy calculates loss based on one value ranging from 0 to 1. In order to avoid overflow, I wanted to be able to raise weight decay to the largest value possible, well Binary Cross Entropy works by sending values through a Sigmoid and then seeing if the value is close to 1, but weight decay pushes these values to 0, which after going through Sigmoid equals 0.5. So, instead I decided to use loss that used Softmax instead. This allows small values to be "highly confident", because if you have two small values (0.0099,0.00001) you can still get large numbers to send into the loss calculation (0.0099/(0.0099+0.00001)).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tanh-Loss">Tanh Loss<a class="anchor-link" href="#Tanh-Loss"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before I talk about why I decided to change up the loss function, I think it is important to understand a bit about CAM loss, which was mentioned previously. CAM loss is based on class activation mapping⁸, and is used in U-GAT-IT as part of a differential loss function. This important thing here is that CAM loss is multiplied by 1000. There are two functions of CAM loss which behave similarly, so for our calculations lets just say that cam loss is 2000<em>loss. The maximum value for fp16 is 65504 so if we divide this by our multiplier we find that we overflow at a loss of approximately 32. Considering the fact that this loss can easily be over 1, we are calculating gradients for every parameter, and we get less precise the closer we get to this maximal value, hard decisions had to be made to simply get this model training on fp16. I decided to send the CAM loss through a hyperbolic tangent, which effectively limits its maximum value to 1, before adding it to the rest of the loss function. This meant that the formula for cam loss went from loss = 2000</em>loss to 2000*tanh(loss). Limiting the maximum value of this loss to 1 downshifts the importance of cam loss in the beginning when the model starting training, but allows it to quickly ramp up when the model starts to get it right. This seems to cause a big shift in the loss when the gradient of this loss is quickly increasing.</p>
<p><insert graph of loss without tanh>,<insert graph of loss with tanh></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Normalization">Normalization<a class="anchor-link" href="#Normalization"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is very important to add that I added extra normalization layers, I have not done proper testing to determine the effect of these layers, but they did decrease the magnitude of the gradients which was the intended effect. All normalization had to of course be done in fp32, whether I added it or it was already part of the network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Weight-Decay-of-0.1">Weight Decay of 0.1<a class="anchor-link" href="#Weight-Decay-of-0.1"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is a very important hyper parameter, because we want to overall network to have as similar of weight/gradients as possible. That way we can fit them easier in the upper bound of overflow, and the lower bound of underflow. Increasing weight decay seemed to allow for higher loss scales.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tooling">Tooling<a class="anchor-link" href="#Tooling"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This work used fastai2⁹, which is much more hackable than previous versions of fastai. I started working on this last October, so at the time there was not very much support for GAN training ported into fastai2. Still, the hackable nature of fastai2 let me work my training loop into the one used for regular image classification and similar tasks. Fastai2 really provides you a great way to help organize your code, even when you are not using models or training loops in a purely out-of-the-box sort of way. The dataloading was also improved in this version, and allowed for things like on GPU data augmentations, and easy way to compose this data pipeline. I also was able to edit much of the code there to add in functionality that I was trying to create.
Having the WandbCallback in fastai was instrumental in tracking training and identifying where I should spend time optimizing training. By tracking gradients in weights and biases¹⁰ as well as all of the other hyper parameters, I was able to easily identify what my current goal should be, as well as have some hope that the network would eventually train. Watching for small improvements in logs over the course of training was the only way I could tell the model was working better in fp16, as the output of the model didn't really improve much.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hardware">Hardware<a class="anchor-link" href="#Hardware"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I hit my the limit of my GPUs a lot during training this model. I was consistently at 99%+ memory utilization on both GPUs, even after the many memory optimizations below. I was training on two 2070 Supers with nvlink during my training run. I had a 2080TI, but found that this was not sufficient. My memory optimizations are listed below. 
Checkpointing
Checkpointing⁵ is the act of not storing the input to a layer when doing the forward pass, and instead calculating it during the backward pass. This is done to save memory on the GPU. Wait, what does that even mean?!? Well, lets look at the chain rule, the derivative of f(g(x)) is f'(g(x))g'(x), notice that the "input" or g(x) is needed to calculate f'(g(x)), checkpointing is simply not storing g(x) for the backward pass when we calculate f(g(x)) during the forward pass.
Using checkpointing was a sad, and very upsetting thing for me. It turned out that I had to use more checkpointing than I originally expected, and checkpointing the smaller fp16 layers did not give the same memory savings as I had hoped. This meant I had to checkpoint much of my network, in order to get the the "magical" batch size of 3 above In the end this meant that I ended up nullifying much of speed advantage I got from training in fp16. Still it was a very great learning experience. If I ever get a larger GPU I would expect the training time to decrease due to the removal of much of the checkpoints.
Model Parallelism</p>
<p>I used a fairly odd solution to my memory problems in the form of model parallelism. This is because I determined that the biggest problem for me was the size of my model, and not the input data or speed. I decided to split my model based on the generator discriminator pairings, because that seemed to require the least information transfer between GPUs. Disclaimer, I did have access to nvlink, which many people may not have access to that was able to speed up the transfer of data between GPUs. This did require me to make copies of my 6 fp16 images on both GPUS, but was much more effective for me because the majority of my GPU memory was going to holding Adam moving averages and non-checkpointed layer's backward passes in memory.
Splitting of Linear Layers</p>
<p>One of the issues I was running into was running out of memory during the optimizer step. This was because of one linear layer of U-GAT-IT having approximately 256*2,000,000 parameters. Holding all of the parameters in memory to do the Adam step calculation meant that I would run out of memory every time I got to this point. So, in order to decrease memory consumption during this step, I split the linear layer into into 32 different linear layers, pass inputs into each, then concatenated the results, before passing that to the next layer as normal.
Zeroing Adam</p>
<p>Normally in PyTorch you zero the gradients after an optimizer step. The above splitting of linear layers was more effective, but I also made a small change to Adam, to go through the parameters smallest to largest, clearing the gradients along the way so that more memory was available for the largest layer's Adam step.
Small Memory optimizations</p>
<p>It is important when working in a memory limited environment that variables are garbage collected early. Especially when that variable is large! Early garbage collection of variables by wrapping memory intensive operations in functions, so they went out of scope was my preferred way of handling this situation. That allowed the code to in general be more expressive and concise.</p>
<Example of Memory Optimization through function>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Limitations">Limitations<a class="anchor-link" href="#Limitations"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One of the issues with my training loop, is that if there is an overflow it will skip to the next batch for the generator. I would prefer to have a set number of actual training iterations, so that is something I would like to improve. I have not yet fully utilize the fp16 speed increase, this is mostly due to memory limitation.
Future Ideas</p>
<p>I am very excited about possibly using NoGan-like architectures to see if I could do away with some of the complexities of GAN training. There are semi-supervised and supervised techniques I would like to try to use to lessen the requirement for exact image to image mapping. Much like as was used in DeOldify⁶. 
GANILLA⁷ is a very similar work, and might allow for some improvements to this model.
The idea of using Sparse operations to save memory might be very useful in a network where I am limited by the sheer number of parameters.
Contact Me, I am looking for a Job</p>
<p>Linked-In Profile: <a href="https://www.linkedin.com/in/molly-beavers-651025118/">https://www.linkedin.com/in/molly-beavers-651025118/</a>
Source Code(WIP): <a href="https://github.com/marii-moe/selfie2anime">https://github.com/marii-moe/selfie2anime</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">References<a class="anchor-link" href="#References"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>[1] Junho Kim, Minjae Kim, Hyeonwoo Kang and Kwang Hee Lee. U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation. International Conference on Learning Representations. 2020 <a href="https://openreview.net/forum?id=BJlZ5ySKPH">https://openreview.net/forum?id=BJlZ5ySKPH</a>
[2] Jun-Yan Zhu<em>, Taesung Park</em>, Phillip Isola, and Alexei A. Efros. "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks", in IEEE International Conference on Computer Vision (ICCV), 2017. (* indicates equal contributions). <a href="https://arxiv.org/pdf/1703.10593.pdf">https://arxiv.org/pdf/1703.10593.pdf</a>
[3] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio."Generative Adversarial Networks." ArXiv, 2014. <a href="https://arxiv.org/abs/1406.2661">https://arxiv.org/abs/1406.2661</a>
[4] Micikevicius, P., Narang, S., Alben, J., Diamos, G.F., Elsen, E., García, D., Ginsburg, B., Houston, M., Kuchaiev, O., Venkatesh, G., &amp; Wu, H."Mixed Precision Training". ArXiv, 2017. <a href="https://arxiv.org/abs/1710.03740">https://arxiv.org/abs/1710.03740</a>
[5] Chen, T., Xu, B., Zhang, C., &amp; Guestrin, C. "Training Deep Nets with Sublinear Memory Cost". ArXiv, 2016. <a href="https://arxiv.org/abs/1604.06174">https://arxiv.org/abs/1604.06174</a>
[6] Jason Antic. "DeOldify". <a href="https://github.com/jantic/DeOldify">https://github.com/jantic/DeOldify</a>
[7] Hicsonmez, Samet &amp; Samet, Nermin &amp; Akbas, Emre &amp; Duygulu, Pinar. "GANILLA: Generative adversarial networks for image to illustration translation". Elsevier Image and Vision Computing 103886, 2020. <a href="https://arxiv.org/abs/2002.05638">https://arxiv.org/abs/2002.05638</a>
[8] Zhou, B. &amp; Khosla, A. and Lapedriza. A. and Oliva, A. and Torralba, A. "Learning Deep Features for Discriminative Localization." CVPR, 2016. <a href="http://cnnlocalization.csail.mit.edu/">http://cnnlocalization.csail.mit.edu/</a>
[9] Howard, J., &amp; Gugger, S. fastai: A Layered API for Deep Learning. ArXiv, 2020. <a href="https://arxiv.org/abs/2002.04688">https://arxiv.org/abs/2002.04688</a>
[10] Biewald, Lukas. "Experiment Tracking with Weights and Biases". 2020. <a href="https://www.wandb.com/">https://www.wandb.com/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">export2html</span><span class="o">.</span><span class="n">notebook2html</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">&#39;Blog_Post.ipynb&#39;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s1">&#39;html/&#39;</span><span class="p">,</span> <span class="n">template_file</span><span class="o">=</span><span class="s1">&#39;fastpages.tpl&#39;</span><span class="p">,</span><span class="n">n_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>converting: Blog_Post.ipynb
</pre>
</div>
</div>

</div>
</div>

</div>
</div>
 

