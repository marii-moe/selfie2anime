{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=untar_data(URLs.MNIST_TINY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#41) [Path('/home/fast/.fastai/data/imagenette-160.tgz'),Path('/home/fast/.fastai/data/imagenette-160'),Path('/home/fast/.fastai/data/mnist.pkl.gz'),Path('/home/fast/.fastai/data/imagenette.tgz'),Path('/home/fast/.fastai/data/imagenette'),Path('/home/fast/.fastai/data/danbooru2018'),Path('/home/fast/.fastai/data/horse2zebra'),Path('/home/fast/.fastai/data/Selfie-dataset'),Path('/home/fast/.fastai/data/oxford-iiit-pet'),Path('/home/fast/.fastai/data/planet_tiny')...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('/home/fast/.fastai/data').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=DataBlock((ImageBlock, CategoryBlock), get_items=get_image_files, splitter=GrandparentSplitter(),\n",
    "                   get_y=parent_label,batch_tfms=aug_transforms(do_flip=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls=db.dataloaders(path,bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=cnn_learner(dls,resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.002290867641568184, 3.6307804407442745e-07)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find(num_it=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.671510</td>\n",
       "      <td>0.095155</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.432407</td>\n",
       "      <td>0.118927</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(2,lr_max=0.014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.lr_find(num_it=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.181299</td>\n",
       "      <td>0.076251</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.234579</td>\n",
       "      <td>0.031906</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.173468</td>\n",
       "      <td>0.038279</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(3,lr_max=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Last Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.callback.wandb import WandbCallback\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/marii/uncategorized\" target=\"_blank\">https://app.wandb.ai/marii/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/marii/uncategorized/runs/kzeqae7t\" target=\"_blank\">https://app.wandb.ai/marii/uncategorized/runs/kzeqae7t</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7fe7dd17cc18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "learner.add_cb(WandbCallback(valid_dl=learner.dls.valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.165175</td>\n",
       "      <td>0.065662</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.116849</td>\n",
       "      <td>0.029303</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.094338</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(3,lr_max=0.0001,moms=(0.5,0.5,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of 5/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GO OVER Adam!!!!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([10,3,32,32])\n",
    "m = nn.Sequential(nn.Conv2d(3,32,7,3,3),nn.Flatten(),nn.Linear(3872,2))\n",
    "l = nn.CrossEntropyLoss()\n",
    "lr=0.1\n",
    "opt=SGD(m.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurSGD:\n",
    "    def __init__(self,params,lr):\n",
    "        self.params,self.lr=params,lr\n",
    "    def step(self):\n",
    "        updated_params=[]\n",
    "        for p in self.params:\n",
    "            updated_params.append(p.add(-self.lr*p.grad))\n",
    "        return updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p-self.lr*p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_sgd=OurSGD(m.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_parameters=our_sgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_step??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def parameters_equal(mps,ops):\n",
    "    for mp,op in zip((mps),ops):\n",
    "        print(mp.allclose(op))\n",
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([10,3,32,32])\n",
    "m = nn.Sequential(nn.Conv2d(3,32,7,3,3),nn.Flatten(),nn.Linear(3872,2))\n",
    "l = nn.CrossEntropyLoss()\n",
    "lr=0.1\n",
    "mom=0.9\n",
    "opt=SGD(m.parameters(),lr,mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgb=ImageBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.data.transforms.ToTensor"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgb.item_tfms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformBlock??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToTensor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformBlock??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataBlock??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurSGDwithMomentum:\n",
    "    def __init__(self,params,lr,mom):\n",
    "        self.params,self.lr=list(params),lr\n",
    "        self.mom=mom ##added\n",
    "        self.avg_grad=[torch.zeros_like(p) for p in self.params] #added\n",
    "    def step(self):\n",
    "        updated_params=[]\n",
    "        for i,p in enumerate(self.params):\n",
    "            updated_params.append(p.add(-self.lr*self.mom_grad(i,p.grad)))\n",
    "        return updated_params\n",
    "    #avg_grad is weighted average using momentum\n",
    "    def mom_grad(self,i,grad):\n",
    "        self.avg_grad[i]=self.mom*self.avg_grad[i]+grad\n",
    "        return self.avg_grad[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_sgd=OurSGDwithMomentum(m.parameters(),lr,mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p-lr*(mom*avg+grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_parameters=our_sgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for step #2! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_parameters=our_sgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SGD with Weight Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SGD Weight Decay and l2_Regularization are effectively the same. One on the weights, one on the gradients. This is not the same for more complicated optimizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([10,3,32,32])\n",
    "m = nn.Sequential(nn.Conv2d(3,32,7,3,3),nn.Flatten(),nn.Linear(3872,2))\n",
    "l = nn.CrossEntropyLoss()\n",
    "lr=0.1\n",
    "mom=0.9\n",
    "wd=0.01\n",
    "opt=SGD(m.parameters(),lr,mom,wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax+by+cz=A\n",
    "a=1000\n",
    "b=0.1\n",
    "c=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self,params,lr,mom):\n",
    "        self.mom=mom\n",
    "        self.params=params\n",
    "        self.avg_grads=[torch.zeros_like(p) for p in self.params] #avg_grad is weighted average using momentum\n",
    "    def __call__(self,**kwargs):\n",
    "        self.avg_grads = [ self.mom*avg_grad+p.grad for p,avg_grad in zip(self.params,self.avg_grads) ]\n",
    "        return {'avg_grads': self.avg_grads,**kwargs}\n",
    "class Weight_Decay:\n",
    "    def __init__(self,params,lr,wd):\n",
    "        self.lr=lr\n",
    "        self.wd=wd\n",
    "        self.params=params\n",
    "    def __call__(self,**kwargs):\n",
    "        return {**kwargs,'params':[p*(1-self.lr*self.wd) for p in self.params]} #same as params-lr*wd*params\n",
    "class OurSGD:\n",
    "    def __init__(self,params,lr,mom,wd):\n",
    "        self.params,self.lr=list(params),lr\n",
    "        self.mom=Momentum(self.params,self.lr,mom)\n",
    "        self.wd=Weight_Decay(self.params,self.lr,wd)\n",
    "    def step(self):\n",
    "        updated_params=[]\n",
    "        self.params=self.wd()['params']\n",
    "        avg_grads=self.mom()['avg_grads']\n",
    "        for i,p in enumerate(self.params):\n",
    "            updated_params.append(p.add(-self.lr*avg_grads[i])) \n",
    "        return updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_sgd=OurSGD(m.parameters(),lr,mom,wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_parameters=our_sgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "opt.zero_grad()\n",
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()\n",
    "our_parameters=our_sgd.step()\n",
    "opt.step()\n",
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SGD with l2 reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l2 reg and weight decay have very similar effects, so no reason to use both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([10,3,32,32])\n",
    "m = nn.Sequential(nn.Conv2d(3,32,7,3,3),nn.Flatten(),nn.Linear(3872,2))\n",
    "l = nn.CrossEntropyLoss()\n",
    "lr=0.1\n",
    "mom=0.9\n",
    "wd=0.01\n",
    "opt=SGD(m.parameters(),lr,mom,wd,decouple_wd= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing a bit of refactoring here to remove momentum and weight decay specific logic here. WE also split off the sgd_specific step while we are at it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self,params=None,lr=0.0001,mom=0.9,**kwargs):\n",
    "        self.mom=mom\n",
    "        self.params=params\n",
    "        self.avg_grads=[torch.zeros_like(p) for p in self.params] #avg_grad is weighted average using momentum\n",
    "    def __call__(self,params=None,**kwargs):\n",
    "        params = self.params if params is None else params\n",
    "        self.avg_grads = [ self.mom*avg_grad+p.grad for p,avg_grad in zip(params,self.avg_grads) ]\n",
    "        return {**kwargs,'params':params,'avg_grads': self.avg_grads}\n",
    "class Weight_Decay:\n",
    "    def __init__(self,params=None,lr=0.0001,wd=0.01,decouple=True,**kwargs):\n",
    "        self.lr=lr\n",
    "        self.wd=wd\n",
    "        self.params=params\n",
    "        self.decouple=decouple\n",
    "    def __call__(self,**kwargs):\n",
    "        params = self._do_wd() if self.decouple else self._do_l2_reg()\n",
    "        return {**kwargs,'params':params}\n",
    "    def _do_wd(self,**kwargs):\n",
    "        params=[p*(1-self.lr*self.wd) for p in self.params]\n",
    "        for p,mp in zip(params,self.params):\n",
    "            p.grad=mp.grad\n",
    "        return params #same as params-lr*wd*params\n",
    "    #this one is pretty ugly \n",
    "    def _do_l2_reg(self,**kwargs):\n",
    "        params=[deepcopy(p) for p in self.params]\n",
    "        for p,mp in zip(params,self.params):\n",
    "            p.grad=mp.grad + self.wd* mp\n",
    "        return params\n",
    "class OurSGD:\n",
    "    hypers=[Weight_Decay,Momentum]\n",
    "    def __init__(self,params,lr,**kwargs):\n",
    "        self.lr=lr\n",
    "        self.params=params\n",
    "    def __call__(self,params=None,avg_grads=None,**kwargs):\n",
    "        return {**kwargs,'params':[ p.add(-self.lr*avg) for p,avg in zip(params,avg_grads) ]}\n",
    "class OurOptimizer:\n",
    "    def __init__(self,params,lr,opt,**kwargs):\n",
    "        self.state={'params':list(params),'lr':lr}\n",
    "        self.cbs=[cls(**self.state,**kwargs) for cls in [*opt.hypers,opt]]\n",
    "    def step(self):\n",
    "        state=self.state\n",
    "        for cb in self.cbs:\n",
    "            state=cb(**state)\n",
    "        return state['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_opt=OurOptimizer(m.parameters(),lr,OurSGD,decouple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_parameters=our_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "opt.zero_grad()\n",
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()\n",
    "our_parameters=our_opt.step()\n",
    "opt.step()\n",
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done with my refactoring. If you notice there is a issue of lots of for...loops going over the same data. In fastai each function momentum/weight_decay/sgd works on a single parameter at a time, and that is encapsulated in a single for...loop, instead of my approach of passing all the parameters to function that does the looping itself. I just got tired of refactoring at this point and decided to keep what I had.... lots of refactoring happened not in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([10,3,32,32])\n",
    "m = nn.Sequential(nn.Conv2d(3,32,7,3,3),nn.Flatten(),nn.Linear(3872,2))\n",
    "l = nn.CrossEntropyLoss()\n",
    "lr=0.1\n",
    "mom=0.9\n",
    "wd=0.01\n",
    "sqr_mom=0.95\n",
    "opt=RMSProp(m.parameters(),lr,sqr_mom,mom,wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self,params=None,lr=0.0001,mom=0.9,**kwargs):\n",
    "        self.mom=mom\n",
    "        self.params=params\n",
    "        self.avg_grads=[torch.zeros_like(p) for p in self.params] #avg_grad is weighted average using momentum\n",
    "    def __call__(self,params=None,**kwargs):\n",
    "        params = self.params if params is None else params\n",
    "        self.avg_grads = [ self.mom*avg_grad+p.grad for p,avg_grad in zip(params,self.avg_grads) ]\n",
    "        return {**kwargs,'params':params,'avg_grads': self.avg_grads}\n",
    "class Weight_Decay:\n",
    "    def __init__(self,params=None,lr=0.0001,wd=0.01,decouple=True,**kwargs):\n",
    "        self.lr=lr\n",
    "        self.wd=wd\n",
    "        self.params=params\n",
    "        self.decouple=decouple\n",
    "    def __call__(self,**kwargs):\n",
    "        params = self._do_wd() if self.decouple else self._do_l2_reg()\n",
    "        return {**kwargs,'params':params}\n",
    "    def _do_wd(self,**kwargs):\n",
    "        params=[p*(1-self.lr*self.wd) for p in self.params]\n",
    "        for p,mp in zip(params,self.params):\n",
    "            p.grad=mp.grad\n",
    "        return params #same as params-lr*wd*params\n",
    "    #this one is pretty ugly \n",
    "    def _do_l2_reg(self,**kwargs):\n",
    "        params=[deepcopy(p) for p in self.params]\n",
    "        for p,mp in zip(params,self.params):\n",
    "            p.grad=mp.grad + self.wd* mp\n",
    "        return params\n",
    "class OurSGD:\n",
    "    hypers=[Weight_Decay,Momentum]\n",
    "    def __init__(self,params,lr,**kwargs):\n",
    "        self.lr=lr\n",
    "        self.params=params\n",
    "    def __call__(self,params=None,avg_grads=None,**kwargs):\n",
    "        return {**kwargs,'params':[ p.add(-self.lr*avg) for p,avg in zip(params,avg_grads) ]}\n",
    "class OurOptimizer:\n",
    "    def __init__(self,params,lr,opt,**kwargs):\n",
    "        self.state={'params':list(params),'lr':lr}\n",
    "        self.cbs=[cls(**self.state,**kwargs) for cls in [*opt.hypers,opt]]\n",
    "    def step(self):\n",
    "        state=self.state\n",
    "        for cb in self.cbs:\n",
    "            state=cb(**state)\n",
    "        return state['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learning_Rate_Decay:\n",
    "    def __init__(self, params=None,sqr_mom=0.99,**kwargs):\n",
    "        self.sqr_mom=sqr_mom\n",
    "        self.sqr_avgs=[torch.zeros_like(p) for p in params]\n",
    "    def __call__(self, params=None, dampening=True, **kwargs):\n",
    "        damp = 1-sqr_mom if dampening else 1.\n",
    "        self.sqr_avgs = [sqr_avg * self.sqr_mom + damp * p.grad.data ** 2 for p,sqr_avg in zip(params,self.sqr_avgs)]\n",
    "        return { **kwargs,'params':params,'sqr_avgs':self.sqr_avgs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurRMSProp:\n",
    "    hypers=[Weight_Decay,Momentum,Learning_Rate_Decay]\n",
    "    def __init__(self,lr,params,**kwargs):\n",
    "        self.lr=lr\n",
    "        self.params=params\n",
    "    def __call__(self,params=None,avg_grads=None,eps=1e-08,sqr_avgs=None,**kwargs):\n",
    "        return {**kwargs,'params':[ p.add(-self.lr*avg/(sqr_avg**(0.5)+eps)) for p,avg,sqr_avg in zip(params,avg_grads,sqr_avgs) ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_opt=OurOptimizer(m.parameters(),lr,OurRMSProp,sqr_mom=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_parameters=our_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "opt.zero_grad()\n",
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()\n",
    "our_parameters=our_opt.step()\n",
    "opt.step()\n",
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([10,3,32,32])\n",
    "m = nn.Sequential(nn.Conv2d(3,32,7,3,3),nn.Flatten(),nn.Linear(3872,2))\n",
    "l = nn.CrossEntropyLoss()\n",
    "lr=0.1\n",
    "mom=0.9\n",
    "wd=0.01\n",
    "eps=1e-05\n",
    "sqr_mom=0.95\n",
    "opt=Adam(m.parameters(),lr,mom,sqr_mom,eps,wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight_Decay:\n",
    "    def __init__(self,params=None,lr=0.0001,wd=0.01,decouple=True,**kwargs):\n",
    "        self.lr=lr\n",
    "        self.wd=wd\n",
    "        self.params=params\n",
    "        self.decouple=decouple\n",
    "    def __call__(self,**kwargs):\n",
    "        params = self._do_wd() if self.decouple else self._do_l2_reg()\n",
    "        return {**kwargs,'params':params}\n",
    "    def _do_wd(self,**kwargs):\n",
    "        params=[p*(1-self.lr*self.wd) for p in self.params]\n",
    "        for p,mp in zip(params,self.params):\n",
    "            p.grad=mp.grad\n",
    "        return params #same as params-lr*wd*params\n",
    "    #this one is pretty ugly \n",
    "    def _do_l2_reg(self,**kwargs):\n",
    "        params=[deepcopy(p) for p in self.params]\n",
    "        for p,mp in zip(params,self.params):\n",
    "            p.grad=mp.grad + self.wd* mp\n",
    "        return params\n",
    "class OurSGD:\n",
    "    hypers=[Weight_Decay,Momentum]\n",
    "    def __init__(self,params,lr,**kwargs):\n",
    "        self.lr=lr\n",
    "        self.params=params\n",
    "    def __call__(self,params=None,avg_grads=None,**kwargs):\n",
    "        return {**kwargs,'params':[ p.add(-self.lr*avg) for p,avg in zip(params,avg_grads) ]}\n",
    "class OurOptimizer:\n",
    "    def __init__(self,params,lr,opt,**kwargs):\n",
    "        self.state={'params':list(params),'lr':lr}\n",
    "        self.cbs=[cls(**self.state,**kwargs) for cls in [*opt.hypers,opt]]\n",
    "    def step(self):\n",
    "        state=self.state\n",
    "        for cb in self.cbs:\n",
    "            state=cb(**state)\n",
    "        return state['params']\n",
    "class Learning_Rate_Decay:\n",
    "    def __init__(self, params=None,sqr_mom=0.99,**kwargs):\n",
    "        self.sqr_mom=sqr_mom\n",
    "        self.sqr_avgs=[torch.zeros_like(p) for p in params]\n",
    "    def __call__(self, params=None, dampening=True, **kwargs):\n",
    "        damp = 1-sqr_mom if dampening else 1.\n",
    "        self.sqr_avgs = [sqr_avg * self.sqr_mom + damp * p.grad.data ** 2 for p,sqr_avg in zip(params,self.sqr_avgs)]\n",
    "        return { **kwargs,'params':params,'sqr_avgs':self.sqr_avgs}\n",
    "class OurRMSProp:\n",
    "    hypers=[Weight_Decay,Momentum,Learning_Rate_Decay]\n",
    "    def __init__(self,lr,params,**kwargs):\n",
    "        self.lr=lr\n",
    "        self.params=params\n",
    "    def __call__(self,params=None,avg_grads=None,eps=1e-08,sqr_avgs=None,**kwargs):\n",
    "        return {**kwargs,'params':[ p.add(-self.lr*avg/(sqr_avg**(0.5)+eps)) for p,avg,sqr_avg in zip(params,avg_grads,sqr_avgs) ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step:\n",
    "    def __init__(self,**kwargs):\n",
    "        self.step=0\n",
    "    def __call__(self,**kwargs):\n",
    "        self.step+=1\n",
    "        return {'step':self.step,**kwargs}\n",
    "class Momentum:\n",
    "    def __init__(self,params=None,lr=0.0001,mom=0.9,**kwargs):\n",
    "        self.mom=mom\n",
    "        self.params=params\n",
    "        self.avg_grads=[torch.zeros_like(p) for p in self.params] #avg_grad is weighted average using momentum\n",
    "    def __call__(self,params=None,**kwargs):\n",
    "        params = self.params if params is None else params\n",
    "        self.avg_grads = [ self.mom*avg_grad+(1-self.mom)*p.grad for p,avg_grad in zip(params,self.avg_grads) ]\n",
    "        return {**kwargs,'params':params,'avg_grads': self.avg_grads}\n",
    "class OurAdam:\n",
    "    hypers=[Weight_Decay,Momentum,Learning_Rate_Decay,Step]\n",
    "    def __init__(self,lr,params,mom=0.9,sqr_mom=0.99,eps=1e-08,**kwargs):\n",
    "        self.lr=lr\n",
    "        self.params=params\n",
    "        self.mom=mom\n",
    "        self.sqr_mom=sqr_mom\n",
    "        self.eps=eps\n",
    "    def __call__(self,step=1,params=None,avg_grads=None,sqr_avgs=None,**kwargs): #eps=1e-08\n",
    "        sqr_avgs=[sqr_avg/(1 - sqr_mom**step) for sqr_avg in sqr_avgs]\n",
    "        avg_grads = [avg_grad / (1 - mom**step) for avg_grad in avg_grads]\n",
    "        return {**kwargs,'params':[ p.addcdiv( -lr ,grad_avg,(sqr_avg.sqrt() + self.eps )) for p,grad_avg,sqr_avg in zip(params,avg_grads,sqr_avgs) ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_opt=OurOptimizer(m.parameters(),lr,OurAdam,eps=eps,sqr_mom=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_parameters=our_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows parameters close to not being equal\n",
    "def parameters_equal_show(mps,ops):\n",
    "    for mp,op in zip((mps),ops):\n",
    "        print(mp.masked_select((mp-op).abs()>1e-08),op.masked_select((mp-op).abs()>1e-08))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1133,  0.1766,  0.2099,  0.1881,  0.1587,  0.2367,  0.2189,  0.2101,\n",
      "         0.1876, -0.2224, -0.2393, -0.1429,  0.2033,  0.1898, -0.1359, -0.1989,\n",
      "        -0.2205,  0.1676, -0.2199, -0.1297, -0.1014, -0.1833, -0.1241, -0.1455,\n",
      "        -0.2361,  0.0979, -0.1395, -0.1275,  0.1032,  0.1991, -0.1265, -0.2069,\n",
      "        -0.2465,  0.2102, -0.0968, -0.2100,  0.1213, -0.1896,  0.1769, -0.2089,\n",
      "        -0.1518,  0.1592,  0.2491,  0.2233, -0.2382, -0.1474,  0.1746, -0.2236,\n",
      "         0.2342, -0.1417,  0.1879, -0.1650, -0.2419, -0.1232, -0.2413, -0.2258,\n",
      "         0.1095, -0.1980, -0.1882, -0.1661, -0.1769,  0.2334, -0.1878,  0.1639,\n",
      "        -0.2143,  0.1531, -0.1679,  0.2016, -0.1644,  0.1493,  0.2032, -0.1417,\n",
      "        -0.1873,  0.1333, -0.1954,  0.1659, -0.1852, -0.1532, -0.1191, -0.2032,\n",
      "         0.2201, -0.1217,  0.1954, -0.1297,  0.2288, -0.1301, -0.2084, -0.2102,\n",
      "        -0.1571, -0.1803, -0.1516,  0.2013, -0.2338, -0.2348,  0.2308, -0.1777,\n",
      "        -0.1932,  0.2142, -0.1990,  0.1751, -0.1063,  0.1684,  0.1321, -0.2281,\n",
      "         0.2266,  0.2006, -0.1572, -0.1618,  0.1587, -0.1836, -0.1399,  0.1631,\n",
      "         0.2076, -0.1600,  0.1584,  0.1980, -0.1637, -0.2027,  0.1153, -0.1639,\n",
      "         0.2354,  0.2395,  0.1963,  0.1393,  0.1422, -0.2111,  0.1376, -0.2402,\n",
      "        -0.1623,  0.2126, -0.2116,  0.1634,  0.2348, -0.1085,  0.1771,  0.1734,\n",
      "         0.2279, -0.0948,  0.2020,  0.1733,  0.1934, -0.2217, -0.1422, -0.2375,\n",
      "         0.1274,  0.0943,  0.1806, -0.2292, -0.2484,  0.0879, -0.0870,  0.2374,\n",
      "        -0.2179,  0.1361, -0.2142,  0.1657,  0.2259,  0.1768, -0.1184,  0.1224,\n",
      "         0.1537,  0.2078, -0.1869,  0.1412, -0.1900,  0.2006,  0.1538, -0.2469,\n",
      "         0.1525,  0.1741, -0.1754, -0.1602,  0.1738, -0.1929, -0.2245, -0.1532,\n",
      "         0.2110, -0.1917, -0.2124, -0.1408,  0.2142,  0.1549,  0.2338,  0.1441,\n",
      "         0.1377, -0.0856,  0.1355,  0.1945,  0.1407, -0.1251, -0.1614, -0.1672,\n",
      "        -0.1015, -0.2143, -0.2052, -0.1670, -0.1607, -0.1440,  0.1313, -0.2089,\n",
      "        -0.1839,  0.1929, -0.1760, -0.1672,  0.1439,  0.2235,  0.1692, -0.2194,\n",
      "         0.2251,  0.2327,  0.1336,  0.2163,  0.1336,  0.1259, -0.1727,  0.2150,\n",
      "         0.1043, -0.2463, -0.1123, -0.2426, -0.1792, -0.2002,  0.1751,  0.2148,\n",
      "         0.1448, -0.1380, -0.1563, -0.1871,  0.1831, -0.2145,  0.1607, -0.1265,\n",
      "        -0.1911,  0.1194, -0.2165,  0.1499, -0.2241,  0.2112, -0.2148,  0.2091,\n",
      "        -0.1458, -0.1751, -0.1461, -0.0967, -0.2017,  0.2188, -0.2264, -0.1651,\n",
      "         0.1476,  0.1527,  0.1455,  0.1243, -0.1918,  0.2038,  0.1374, -0.1014,\n",
      "         0.1878,  0.1480,  0.2019, -0.2465,  0.1896, -0.0874,  0.1408,  0.1890,\n",
      "        -0.1063, -0.1180,  0.2152, -0.2209, -0.0888, -0.1289, -0.0962, -0.1288,\n",
      "        -0.1128, -0.2351, -0.1592,  0.2114, -0.1509,  0.1655,  0.1508, -0.2424,\n",
      "         0.1167, -0.1288,  0.1192,  0.2172,  0.2097,  0.1360,  0.1987,  0.1679,\n",
      "        -0.2080,  0.1977,  0.1119, -0.2058,  0.2321, -0.2175,  0.1355, -0.1258,\n",
      "         0.2299, -0.1452,  0.1001,  0.2152,  0.1421,  0.1147,  0.2330, -0.1812,\n",
      "        -0.2164, -0.1955, -0.2077,  0.0908, -0.1649,  0.1881, -0.1824,  0.2457,\n",
      "        -0.2432,  0.1121, -0.1637, -0.2450,  0.1257, -0.1627,  0.1748,  0.2427,\n",
      "        -0.1599, -0.1931, -0.1066,  0.1651, -0.1312, -0.1043, -0.2015, -0.1110,\n",
      "         0.1249,  0.1858,  0.2090,  0.1888, -0.1954, -0.2169,  0.2114,  0.1973,\n",
      "        -0.2127, -0.2306,  0.2417, -0.2018,  0.1643, -0.1919,  0.1861, -0.2181,\n",
      "         0.1240,  0.1651, -0.1849,  0.1898,  0.2095, -0.1603,  0.2033,  0.1576,\n",
      "         0.2191, -0.2073,  0.1760, -0.2221,  0.2012, -0.2427, -0.2261, -0.2418,\n",
      "         0.0866, -0.1986,  0.1042,  0.1729, -0.2225,  0.2179, -0.2128, -0.2064,\n",
      "         0.0927, -0.1463, -0.1697, -0.1840, -0.1575, -0.1765, -0.1417, -0.2115,\n",
      "         0.2077,  0.1541, -0.1145,  0.2130, -0.2225, -0.1029, -0.1301,  0.2200,\n",
      "        -0.1071, -0.2340,  0.1184, -0.1121,  0.2498, -0.1454, -0.1599, -0.1192,\n",
      "         0.2128, -0.2047, -0.1026, -0.1550,  0.1381,  0.1884, -0.1259,  0.1918,\n",
      "        -0.1030, -0.1590, -0.2230,  0.2229, -0.2175,  0.1678, -0.2143, -0.1747,\n",
      "        -0.1552,  0.1536,  0.1499,  0.1595, -0.1967, -0.1533, -0.2196,  0.1193,\n",
      "        -0.1477,  0.2348,  0.2465, -0.2066,  0.1739, -0.1321,  0.2126,  0.1777,\n",
      "        -0.1872,  0.1361, -0.2462,  0.1694,  0.1474,  0.1672,  0.1734, -0.1947,\n",
      "         0.1702, -0.1690,  0.1698, -0.1295,  0.1401, -0.1864, -0.1566,  0.1362,\n",
      "         0.1980,  0.1747, -0.2286, -0.1648,  0.2033, -0.1179,  0.1884,  0.1921,\n",
      "        -0.2183,  0.2279, -0.2139, -0.0851,  0.2477,  0.1419, -0.1451, -0.1677,\n",
      "         0.2460,  0.2305,  0.1868, -0.2343, -0.1505,  0.2287,  0.1314,  0.2475,\n",
      "        -0.1446, -0.1734,  0.1849,  0.1168, -0.2334, -0.2158, -0.2291, -0.2386,\n",
      "         0.1709, -0.2310, -0.1924, -0.2474, -0.1943, -0.2114, -0.2292,  0.1596,\n",
      "        -0.2397,  0.2005,  0.1538, -0.2183, -0.2213,  0.1287,  0.1810,  0.1724,\n",
      "         0.1620, -0.1071,  0.1933,  0.2109, -0.2471, -0.1865,  0.2191,  0.1049,\n",
      "         0.1630,  0.1005, -0.1664,  0.1153,  0.1687, -0.0914, -0.2499,  0.1455,\n",
      "        -0.1582, -0.2422, -0.1850,  0.1949,  0.2278,  0.1610, -0.1282,  0.2283,\n",
      "         0.2352,  0.1533, -0.2019, -0.1028,  0.1885,  0.1379,  0.1058,  0.1140,\n",
      "        -0.2087, -0.1397, -0.1373,  0.2404,  0.2000, -0.1603,  0.1448, -0.2044,\n",
      "         0.1402,  0.2451,  0.1484,  0.1715,  0.2371, -0.1006,  0.1071, -0.1647,\n",
      "         0.1361, -0.1388, -0.1953, -0.2061,  0.1237, -0.2190, -0.2424,  0.2041,\n",
      "         0.2076, -0.2180, -0.1903, -0.1864,  0.1390,  0.2429,  0.1950,  0.2327,\n",
      "        -0.1784, -0.2185,  0.1452,  0.1724,  0.0899, -0.0891, -0.1403,  0.1413,\n",
      "         0.2000,  0.1347, -0.2395, -0.1211,  0.1891, -0.1858,  0.2475,  0.2388,\n",
      "        -0.1659, -0.2133,  0.2159,  0.2232,  0.1672,  0.1641, -0.2145,  0.1735,\n",
      "        -0.1986,  0.1812,  0.1669, -0.1667, -0.1812, -0.1491, -0.1656,  0.2409,\n",
      "        -0.1922,  0.1408, -0.1686,  0.2273, -0.1791, -0.1835, -0.1541, -0.1754,\n",
      "         0.2418,  0.2302,  0.2209, -0.1581, -0.1870,  0.1369,  0.2049,  0.2351,\n",
      "         0.2441,  0.2287,  0.2472, -0.1304,  0.2357,  0.1048, -0.2482,  0.1144,\n",
      "         0.1021, -0.1148,  0.1297,  0.1271,  0.1215,  0.1378],\n",
      "       grad_fn=<MaskedSelectBackward>) tensor([ 0.1133,  0.1766,  0.2099,  0.1881,  0.1587,  0.2367,  0.2189,  0.2101,\n",
      "         0.1876, -0.2224, -0.2393, -0.1429,  0.2033,  0.1898, -0.1359, -0.1989,\n",
      "        -0.2205,  0.1676, -0.2199, -0.1297, -0.1014, -0.1833, -0.1241, -0.1455,\n",
      "        -0.2361,  0.0979, -0.1395, -0.1275,  0.1032,  0.1991, -0.1265, -0.2069,\n",
      "        -0.2465,  0.2102, -0.0968, -0.2100,  0.1213, -0.1896,  0.1769, -0.2089,\n",
      "        -0.1518,  0.1592,  0.2491,  0.2233, -0.2382, -0.1474,  0.1746, -0.2236,\n",
      "         0.2342, -0.1417,  0.1879, -0.1650, -0.2419, -0.1232, -0.2413, -0.2258,\n",
      "         0.1095, -0.1980, -0.1882, -0.1661, -0.1769,  0.2334, -0.1878,  0.1639,\n",
      "        -0.2143,  0.1531, -0.1679,  0.2016, -0.1644,  0.1493,  0.2032, -0.1417,\n",
      "        -0.1873,  0.1333, -0.1954,  0.1659, -0.1852, -0.1532, -0.1191, -0.2032,\n",
      "         0.2201, -0.1217,  0.1954, -0.1297,  0.2288, -0.1301, -0.2084, -0.2102,\n",
      "        -0.1571, -0.1803, -0.1516,  0.2013, -0.2338, -0.2348,  0.2308, -0.1777,\n",
      "        -0.1932,  0.2142, -0.1990,  0.1751, -0.1063,  0.1684,  0.1321, -0.2281,\n",
      "         0.2266,  0.2006, -0.1572, -0.1618,  0.1587, -0.1836, -0.1399,  0.1631,\n",
      "         0.2076, -0.1600,  0.1584,  0.1980, -0.1637, -0.2027,  0.1153, -0.1639,\n",
      "         0.2354,  0.2395,  0.1963,  0.1393,  0.1422, -0.2111,  0.1376, -0.2402,\n",
      "        -0.1623,  0.2126, -0.2116,  0.1634,  0.2348, -0.1085,  0.1771,  0.1734,\n",
      "         0.2279, -0.0948,  0.2020,  0.1733,  0.1934, -0.2217, -0.1422, -0.2375,\n",
      "         0.1274,  0.0943,  0.1806, -0.2292, -0.2484,  0.0879, -0.0870,  0.2374,\n",
      "        -0.2179,  0.1361, -0.2142,  0.1657,  0.2259,  0.1768, -0.1184,  0.1224,\n",
      "         0.1537,  0.2078, -0.1869,  0.1412, -0.1900,  0.2006,  0.1538, -0.2469,\n",
      "         0.1525,  0.1741, -0.1754, -0.1602,  0.1738, -0.1929, -0.2245, -0.1532,\n",
      "         0.2110, -0.1917, -0.2124, -0.1408,  0.2142,  0.1549,  0.2338,  0.1441,\n",
      "         0.1377, -0.0856,  0.1355,  0.1945,  0.1407, -0.1251, -0.1614, -0.1672,\n",
      "        -0.1015, -0.2143, -0.2052, -0.1670, -0.1607, -0.1440,  0.1313, -0.2089,\n",
      "        -0.1839,  0.1929, -0.1760, -0.1672,  0.1439,  0.2235,  0.1692, -0.2194,\n",
      "         0.2251,  0.2327,  0.1336,  0.2163,  0.1336,  0.1259, -0.1727,  0.2150,\n",
      "         0.1043, -0.2463, -0.1123, -0.2426, -0.1792, -0.2002,  0.1751,  0.2148,\n",
      "         0.1448, -0.1380, -0.1563, -0.1871,  0.1831, -0.2145,  0.1607, -0.1265,\n",
      "        -0.1911,  0.1194, -0.2165,  0.1499, -0.2241,  0.2112, -0.2148,  0.2091,\n",
      "        -0.1458, -0.1751, -0.1461, -0.0967, -0.2017,  0.2188, -0.2264, -0.1651,\n",
      "         0.1476,  0.1527,  0.1455,  0.1243, -0.1918,  0.2038,  0.1374, -0.1014,\n",
      "         0.1878,  0.1480,  0.2019, -0.2465,  0.1896, -0.0874,  0.1408,  0.1890,\n",
      "        -0.1063, -0.1180,  0.2152, -0.2209, -0.0888, -0.1289, -0.0962, -0.1288,\n",
      "        -0.1128, -0.2351, -0.1592,  0.2114, -0.1509,  0.1655,  0.1508, -0.2424,\n",
      "         0.1167, -0.1288,  0.1192,  0.2172,  0.2097,  0.1360,  0.1987,  0.1679,\n",
      "        -0.2080,  0.1977,  0.1119, -0.2058,  0.2321, -0.2175,  0.1355, -0.1258,\n",
      "         0.2299, -0.1452,  0.1001,  0.2152,  0.1421,  0.1147,  0.2330, -0.1812,\n",
      "        -0.2164, -0.1955, -0.2077,  0.0908, -0.1649,  0.1881, -0.1824,  0.2457,\n",
      "        -0.2432,  0.1121, -0.1637, -0.2450,  0.1257, -0.1627,  0.1748,  0.2427,\n",
      "        -0.1599, -0.1931, -0.1066,  0.1651, -0.1312, -0.1043, -0.2015, -0.1110,\n",
      "         0.1249,  0.1858,  0.2090,  0.1888, -0.1954, -0.2169,  0.2114,  0.1973,\n",
      "        -0.2127, -0.2306,  0.2417, -0.2018,  0.1643, -0.1919,  0.1861, -0.2181,\n",
      "         0.1240,  0.1651, -0.1849,  0.1898,  0.2095, -0.1603,  0.2033,  0.1576,\n",
      "         0.2191, -0.2073,  0.1760, -0.2221,  0.2012, -0.2427, -0.2261, -0.2418,\n",
      "         0.0866, -0.1986,  0.1042,  0.1729, -0.2225,  0.2179, -0.2128, -0.2064,\n",
      "         0.0927, -0.1463, -0.1697, -0.1840, -0.1575, -0.1765, -0.1417, -0.2115,\n",
      "         0.2077,  0.1541, -0.1145,  0.2130, -0.2225, -0.1029, -0.1301,  0.2200,\n",
      "        -0.1071, -0.2340,  0.1184, -0.1121,  0.2498, -0.1454, -0.1599, -0.1192,\n",
      "         0.2128, -0.2047, -0.1026, -0.1550,  0.1381,  0.1884, -0.1259,  0.1918,\n",
      "        -0.1030, -0.1590, -0.2230,  0.2229, -0.2175,  0.1678, -0.2143, -0.1747,\n",
      "        -0.1552,  0.1536,  0.1499,  0.1595, -0.1967, -0.1533, -0.2196,  0.1193,\n",
      "        -0.1477,  0.2348,  0.2465, -0.2066,  0.1739, -0.1321,  0.2126,  0.1777,\n",
      "        -0.1872,  0.1361, -0.2462,  0.1694,  0.1474,  0.1672,  0.1734, -0.1947,\n",
      "         0.1702, -0.1690,  0.1698, -0.1295,  0.1401, -0.1864, -0.1566,  0.1362,\n",
      "         0.1980,  0.1747, -0.2286, -0.1648,  0.2033, -0.1179,  0.1884,  0.1921,\n",
      "        -0.2183,  0.2279, -0.2139, -0.0851,  0.2477,  0.1419, -0.1451, -0.1677,\n",
      "         0.2460,  0.2305,  0.1868, -0.2343, -0.1505,  0.2287,  0.1314,  0.2475,\n",
      "        -0.1446, -0.1734,  0.1849,  0.1168, -0.2334, -0.2158, -0.2291, -0.2386,\n",
      "         0.1709, -0.2310, -0.1924, -0.2474, -0.1943, -0.2114, -0.2292,  0.1596,\n",
      "        -0.2397,  0.2005,  0.1538, -0.2183, -0.2213,  0.1287,  0.1810,  0.1724,\n",
      "         0.1620, -0.1071,  0.1933,  0.2109, -0.2471, -0.1865,  0.2191,  0.1049,\n",
      "         0.1630,  0.1005, -0.1664,  0.1153,  0.1687, -0.0914, -0.2499,  0.1455,\n",
      "        -0.1582, -0.2422, -0.1850,  0.1949,  0.2278,  0.1610, -0.1282,  0.2283,\n",
      "         0.2352,  0.1533, -0.2019, -0.1028,  0.1885,  0.1379,  0.1058,  0.1140,\n",
      "        -0.2087, -0.1397, -0.1373,  0.2404,  0.2000, -0.1603,  0.1448, -0.2044,\n",
      "         0.1402,  0.2451,  0.1484,  0.1715,  0.2371, -0.1006,  0.1071, -0.1647,\n",
      "         0.1361, -0.1388, -0.1953, -0.2061,  0.1237, -0.2190, -0.2424,  0.2041,\n",
      "         0.2076, -0.2180, -0.1903, -0.1864,  0.1390,  0.2429,  0.1950,  0.2327,\n",
      "        -0.1784, -0.2185,  0.1452,  0.1724,  0.0899, -0.0891, -0.1403,  0.1413,\n",
      "         0.2000,  0.1347, -0.2395, -0.1211,  0.1891, -0.1858,  0.2475,  0.2388,\n",
      "        -0.1659, -0.2133,  0.2159,  0.2232,  0.1672,  0.1641, -0.2145,  0.1735,\n",
      "        -0.1986,  0.1812,  0.1669, -0.1667, -0.1812, -0.1491, -0.1656,  0.2409,\n",
      "        -0.1922,  0.1408, -0.1686,  0.2273, -0.1791, -0.1835, -0.1541, -0.1754,\n",
      "         0.2418,  0.2302,  0.2209, -0.1581, -0.1870,  0.1369,  0.2049,  0.2351,\n",
      "         0.2441,  0.2287,  0.2472, -0.1304,  0.2357,  0.1048, -0.2482,  0.1144,\n",
      "         0.1021, -0.1148,  0.1297,  0.1271,  0.1215,  0.1378],\n",
      "       grad_fn=<MaskedSelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "parameters_equal_show(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "opt.zero_grad()\n",
    "pred=m(x)\n",
    "loss=l(pred,torch.zeros([pred.size()[0]],dtype=torch.long))\n",
    "loss.backward()\n",
    "our_parameters=our_opt.step()\n",
    "opt.step()\n",
    "parameters_equal(m.parameters(),our_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [{'wd': 0.01, 'sqr_mom': 0.95, 'lr': 0.1, 'mom': 0.9, 'eps': 1e-05}]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataBlock??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai2)",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
