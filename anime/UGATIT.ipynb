{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp anime.ugatit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from fast.torch_basics import *\n",
    "import sys\n",
    "class fakemodule(object):\n",
    "    def method(a):\n",
    "        return a\n",
    "sys.modules[\"cv2\"] = fakemodule\n",
    "from UGATIT import ResnetGenerator,Discriminator,RhoClipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path(\"/home/fast/fastai_dev/anime/\")\n",
    "x=np.load(str(path/'ugatit.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UGATIT(object) :\n",
    "    def __init__(self):\n",
    "        self.ch = 64\n",
    "        self.lr=0.0001\n",
    "        self.weight_decay=0.0001\n",
    "        \"\"\" Weight \"\"\"\n",
    "        self.cycle_weight = 10\n",
    "        self.identity_weight = 10\n",
    "        self.cam_weight = 1000\n",
    "\n",
    "        \"\"\" Generator \"\"\"\n",
    "        self.n_res = 4\n",
    "\n",
    "        \"\"\" Discriminator \"\"\"\n",
    "        self.n_dis = 6\n",
    "\n",
    "        self.img_size = 128\n",
    "        self.img_ch = 3\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        \"\"\" Define Generator, Discriminator \"\"\"\n",
    "        genA2B = ResnetGenerator(input_nc=3, output_nc=3, ngf=self.ch, n_blocks=self.n_res, img_size=self.img_size, light=False)\n",
    "        genB2A = ResnetGenerator(input_nc=3, output_nc=3, ngf=self.ch, n_blocks=self.n_res, img_size=self.img_size, light=False)\n",
    "        disGA = Discriminator(input_nc=3, ndf=self.ch, n_layers=7)\n",
    "        disGB = Discriminator(input_nc=3, ndf=self.ch, n_layers=7)\n",
    "        disLA = Discriminator(input_nc=3, ndf=self.ch, n_layers=5)\n",
    "        disLB = Discriminator(input_nc=3, ndf=self.ch, n_layers=5)\n",
    "        genA2B.name='genA2B'\n",
    "        genB2A.name='genB2A'\n",
    "        disGA.name='disGA'\n",
    "        disGB.name='disGB'\n",
    "        disLA.name='disLA'\n",
    "        disLB.name='disLB'\n",
    "        self.models=(genA2B,genB2A,disGA,disGB,disLA,disLB)\n",
    "        \n",
    "\n",
    "        \"\"\" Define Loss \"\"\"\n",
    "        L1_loss = nn.L1Loss()\n",
    "        MSE_loss = nn.MSELoss()\n",
    "        BCE_loss = nn.BCEWithLogitsLoss()\n",
    "        self.losses=(L1_loss,MSE_loss,BCE_loss)\n",
    "\n",
    "        \"\"\" Trainer \"\"\"\n",
    "        G_optim = torch.optim.Adam(itertools.chain(genA2B.parameters(), genB2A.parameters()), lr=self.lr, betas=(0.5, 0.999), weight_decay=self.weight_decay)\n",
    "        D_optim = torch.optim.Adam(itertools.chain(disGA.parameters(), disGB.parameters(), disLA.parameters(), disLB.parameters()), lr=self.lr, betas=(0.5, 0.999), weight_decay=self.weight_decay)\n",
    "        G_optim.name='gen_optim'\n",
    "        D_optim.name='disc_optim'\n",
    "        self.optims=(G_optim,D_optim)\n",
    "        \n",
    "        \"\"\" Define Rho clipper to constraint the value of rho in AdaILN and ILN\"\"\"\n",
    "        self.Rho_clipper = RhoClipper(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UgatitModel(nn.Module):\n",
    "    def __init__(self,models):\n",
    "        super(UgatitModel, self).__init__()\n",
    "        keys=['GA2B','GB2A','DA','DB','LA','LB']\n",
    "        self.models=nn.ModuleDict(zip(keys,models))\n",
    "        self.optimizing_gen=True\n",
    "    def forward(self, *x, **kwargs):\n",
    "        x_a,x_b=x[0] if len(x)==1 else x #hackery depending on pytorch trace flag, input can be different\n",
    "        if self.training:\n",
    "            if self.optimizing_gen:\n",
    "                fakeA2B,fakeB2A=self.models['GA2B'](x_a),self.models['GB2A'](x_b)\n",
    "                return (fakeA2B,fakeB2A,\n",
    "                    self.models['GB2A'](x_a),self.models['GA2B'](x_b),\n",
    "                    self.models['DA'](fakeB2A[0]),self.models['LA'](fakeB2A[0]),self.models['DB'](fakeA2B[0]),self.models['LB'](fakeA2B[0]),\n",
    "                    self.models['GB2A'](fakeA2B[0]),self.models['GA2B'](fakeB2A[0]))\n",
    "            else:\n",
    "                fakeA2B,fakeB2A=self.models['GA2B'](x_a)[0],self.models['GB2A'](x_b)[0] #storing forward pass not needed?\n",
    "                return (self.models['DA'](x_a),self.models['LA'](x_a),self.models['DB'](x_b),self.models['LB'](x_b),\n",
    "                    self.models['DA'](fakeB2A),self.models['LA'](fakeB2A),self.models['DB'](fakeA2B),self.models['LB'](fakeA2B))\n",
    "        else: \n",
    "            fakeA2B,fakeB2A=self.models['GA2B'](x_a),self.models['GB2A'](x_b)\n",
    "            return (fakeA2B,fakeB2A,\n",
    "                self.models['GB2A'](x_a),self.models['GA2B'](x_b),\n",
    "                self.models['DA'](fakeB2A[0]),self.models['LA'](fakeB2A[0]),self.models['DB'](fakeA2B[0]),self.models['LB'](fakeA2B[0]),\n",
    "                self.models['GB2A'](fakeA2B[0]),self.models['GA2B'](fakeB2A[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UGATITLoss():\n",
    "    def __init__(self,cycle_weight = 10,identity_weight = 10,cam_weight = 1000,adv_weight=1):\n",
    "        store_attr(self, \"cycle_weight,identity_weight,cam_weight,adv_weight\")\n",
    "        self.MSE_loss=nn.MSELoss()\n",
    "        self.L1_loss=nn.L1Loss()\n",
    "        self.BCE_loss=nn.BCEWithLogitsLoss()\n",
    "        self.loss_funcs=[self.MSE_loss,self.L1_loss,self.BCE_loss]\n",
    "        self.losses=(self.GeneratorLoss(self),self.DiscriminatorLoss(self))\n",
    "        \n",
    "    #xb should be pred, need to figure out what to do here\n",
    "    def __call__(self,xb,yb):\n",
    "        return self.generator_loss(xb,yb)\n",
    "            \n",
    "    def cam_loss(self,fake_A2B_cam_logit,fake_B2B_cam_logit):\n",
    "        return self.BCE_loss(fake_A2B_cam_logit, torch.ones_like(fake_A2B_cam_logit)) \\\n",
    "            + self.BCE_loss(fake_B2B_cam_logit, torch.zeros_like(fake_B2B_cam_logit))\n",
    "\n",
    "    def ad_loss(self,probs,target_value=1):\n",
    "        prob, cam_prob, _ = probs\n",
    "        ad_loss = self.MSE_loss(prob, torch.full_like(prob,fill_value=target_value))\n",
    "        ad_cam_loss = self.MSE_loss(cam_prob, torch.full_like(cam_prob,fill_value=target_value))\n",
    "        return  ad_loss + ad_cam_loss\n",
    "    class GeneratorLoss(nn.Module):\n",
    "        def __init__(self,ugatit_loss):\n",
    "            super(UGATITLoss.GeneratorLoss, self).__init__()\n",
    "            self.ugatit_loss=ugatit_loss\n",
    "            self.losses=nn.ModuleList(self.ugatit_loss.loss_funcs)\n",
    "        def decodes(self,preds):\n",
    "            return ((TensorImage(preds[0][0]),TensorImage(preds[1][0])),)\n",
    "        def __call__(self,pred,yb):\n",
    "            real_A,real_B=yb\n",
    "            u=self.ugatit_loss\n",
    "            fake_A2B, fake_A2B_cam_logit, _ = pred[0]\n",
    "            fake_B2A, fake_B2A_cam_logit, _ = pred[1]\n",
    "\n",
    "            fake_A2A, fake_A2A_cam_logit, _ = pred[2]\n",
    "            fake_B2B, fake_B2B_cam_logit, _ = pred[3]\n",
    "            \n",
    "            predDA_on_B2A,predLA_on_B2A,predDB_on_A2B,predLB_on_A2B=pred[4],pred[5],pred[6],pred[7]\n",
    "\n",
    "            fake_cycle_A,_,_ = pred[8]\n",
    "            fake_cycle_B,_,_= pred[9]                          \n",
    "                                           \n",
    "            ad_loss_A = u.ad_loss(predDA_on_B2A) + u.ad_loss(predLA_on_B2A)\n",
    "            ad_loss_B = u.ad_loss(predDB_on_A2B) + u.ad_loss(predLB_on_A2B)\n",
    "            loss = ad_loss_A + ad_loss_B\n",
    "\n",
    "            cycle_loss_A = u.L1_loss(fake_cycle_A,real_A)\n",
    "            cycle_loss_B = u.L1_loss(fake_cycle_B,real_B)\n",
    "            loss += u.cycle_weight * (cycle_loss_A + cycle_loss_B)\n",
    "\n",
    "            identity_loss_A = u.L1_loss(fake_A2A, real_A)\n",
    "            identity_loss_B = u.L1_loss(fake_B2B, real_B)\n",
    "            loss += u.identity_weight * (identity_loss_A + identity_loss_B)\n",
    "\n",
    "            cam_loss_A = u.cam_loss(fake_B2A_cam_logit,fake_A2A_cam_logit)\n",
    "            cam_loss_B = u.cam_loss(fake_A2B_cam_logit,fake_B2B_cam_logit)\n",
    "            return loss + u.cam_weight * (cam_loss_A + cam_loss_B)\n",
    "\n",
    "    class DiscriminatorLoss(nn.Module):\n",
    "        def __init__(self,ugatit):\n",
    "            super(UGATITLoss.DiscriminatorLoss, self).__init__()\n",
    "            self.ugatit=ugatit\n",
    "            self.mse=self.ugatit.MSE_loss\n",
    "            \n",
    "        def __call__(self,pred,yb):\n",
    "            u=self.ugatit\n",
    "\n",
    "            #Need to replace with adversarial loss, three variable ones/zeros_like, img, discriminator\n",
    "            loss = u.ad_loss(pred[0])\n",
    "            loss += u.ad_loss(pred[1])\n",
    "            loss += u.ad_loss(pred[2])\n",
    "            loss += u.ad_loss(pred[3])\n",
    "            loss += u.ad_loss(pred[4],target_value=0)\n",
    "            loss += u.ad_loss(pred[5],target_value=0)\n",
    "            loss += u.ad_loss(pred[6],target_value=0)\n",
    "            loss += u.ad_loss(pred[7],target_value=0)\n",
    "\n",
    "            return u.adv_weight * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugatit=UGATIT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugatit.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResnetGenerator:\n\tMissing key(s) in state_dict: \"FC.2.bias\", \"FC.3.weight\", \"FC.5.weight\", \"FC.5.bias\". \n\tsize mismatch for FC.2.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([256]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0299b580eebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mugatit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai_dev/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResnetGenerator:\n\tMissing key(s) in state_dict: \"FC.2.bias\", \"FC.3.weight\", \"FC.5.weight\", \"FC.5.bias\". \n\tsize mismatch for FC.2.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([256])."
     ]
    }
   ],
   "source": [
    "for model in ugatit.models:\n",
    "    model.load_state_dict(torch.load(path/(model.name+'.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=UGATITLoss()\n",
    "discriminator_loss=loss.losses[1]\n",
    "generator_loss=loss.losses[0]\n",
    "fx=torch.FloatTensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genA2B',\n",
       " 'genB2A',\n",
       " 'disGA',\n",
       " 'disGB',\n",
       " 'disLA',\n",
       " 'disLB',\n",
       " 'gen_optim',\n",
       " 'disc_optim']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ model.name for model in ugatit.models+ugatit.optims ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to fix BELOW!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for model in ugatit.models: model.train()\n",
    "ugatit.optims[1].zero_grad()\n",
    "l=discriminator_loss((fx[0],fx[1]))\n",
    "print(l.item())\n",
    "l.backward()\n",
    "ugatit.optims[1].step()\n",
    "ugatit.optims[0].zero_grad()\n",
    "l=generator_loss(fx[0],fx[1])\n",
    "print(l.item())\n",
    "l.backward()\n",
    "ugatit.optims[0].step()\n",
    "for model in ugatit.models:\n",
    "    if(model.name=='genA2B' or model.name=='genB2A'):\n",
    "        model.apply(ugatit.Rho_clipper)\n",
    "\n",
    "discriminator_loss((fx[0],fx[1])),generator_loss(fx[0],fx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Dataloading Original.ipynb.\n",
      "Converted Dataloading-Dec31.ipynb.\n",
      "Converted Dataloading-Oct22.ipynb.\n",
      "Converted Dataloading.ipynb.\n",
      "Converted Dataloading_10_14_2019.ipynb.\n",
      "Converted Kernel Inception Distance.ipynb.\n",
      "Converted TensorboardCallback.ipynb.\n",
      "Converted UGATIT-Dec31Backup.ipynb.\n",
      "Converted UGATIT.ipynb.\n",
      "Converted UGATIT_Original.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from fast.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
